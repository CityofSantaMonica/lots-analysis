{
 "metadata": {
  "name": "",
  "signature": "sha256:703aed2e17a744254bd5ecd86855ebaa593d2de61a2e39f1fec43ecaf7a75262"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Lots Analysis\n",
      "\n",
      "A project to analyze parking lot data in Santa Monica. \n",
      "\n",
      "The primary data source is the [City of Santa Monica's Open Data Portal](https://data.smgov.net),\n",
      "and specifically the [Parking Lot Counts](https://data.smgov.net/Transportation/Parking-Lot-Counts/ng8m-khuz) dataset.\n",
      "\n",
      "This dataset is fed a snapshot of the [current state of the parking lots](https://parking.api.smgov.net/lots) every 5 minutes, 24 hours a day.\n",
      "\n",
      "## Data acquisition\n",
      "\n",
      "We start by acquiring lot count data from the previous year:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from datetime import date\n",
      "import pandas, urllib\n",
      "\n",
      "data_year = date.today().year - 1\n",
      "\n",
      "params = {\n",
      "    \"$where\": \"date_time between '{0}-01-01T00:00' and '{0}-12-31T23:59'\".format(data_year),\n",
      "    \"$limit\": 100000\n",
      "}\n",
      "\n",
      "base_url = \"https://data.smgov.net/resource/tce2-7ir6.json?\"\n",
      "query = urllib.urlencode(params)\n",
      "\n",
      "# historical dataframe\n",
      "hdf = pandas.read_json(base_url + query)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "continue by reading the static CSV data:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# static dataframe\n",
      "sdf = pandas.read_csv(\"https://raw.githubusercontent.com/CityofSantaMonica/lots-analysis/improved-merge/static.csv\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Data Preprocessing\n",
      "\n",
      "Before analysis can begin, ee need to cleanup and normalize the data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# renaming columns in the static data\n",
      "sdf.rename(\n",
      "    columns = { \"Total Spaces\": \"total_spaces\" },\n",
      "    inplace = True\n",
      ")\n",
      "\n",
      "# clean up addresses in historical data to match those in static data\n",
      "hdf.street_address = hdf.street_address.replace(\n",
      "    [r\", Santa Monica\", r\"\\.\", r\"\\bSt\\b\", r\"\\sat 4th Street\"],\n",
      "    [               \"\",    \"\",  \"Street\",                 \"\"],\n",
      "    regex = True\n",
      ")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Merging historic and static data\n",
      "\n",
      "The analysis job will be easier if we have a single DataFrame to work from, taking corresponding columns from both the static and historic DataFrames:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "# merge on the address columns, taking only a sub-set of the merged columns\n",
      "df = hdf.merge(sdf, left_on = \"street_address\", right_on = \"Address\")[[\n",
      "    \"date_time\",\n",
      "    \"lot_name\",\n",
      "    \"available_spaces\",\n",
      "    \"total_spaces\",\n",
      "    \"street_address\",\n",
      "    \"zip_code\",\n",
      "    \"latitude\",\n",
      "    \"longitude\"\n",
      "]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Enriching the data\n",
      "\n",
      "We'll calculate in some values based on other columns, to have more data to play with for analysis"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# create columns for date-derived features\n",
      "df[\"hour\"] = df.date_time.apply(lambda x: x.hour + (x.minute / 60.0))\n",
      "\n",
      "for feature in [\"day\", \"week\", \"month\", \"quarter\"]:\n",
      "    df[feature] = df.date_time.apply(lambda x: getattr(x, feature))\n",
      "\n",
      "# fix instances where there are more available than total spaces\n",
      "mask = df.available_spaces > df.total_spaces\n",
      "df.loc[mask, \"available_spaces\"] = df.loc[mask, \"total_spaces\"]\n",
      "   \n",
      "# calc in an availability score\n",
      "df[\"availability\"] = df.available_spaces / df.total_spaces"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Analysis\n",
      "\n",
      "Now that we have a nice set of historical data, joined with the static lot information, we can begin to do some analysis.\n",
      "\n",
      "[A naive approach](naive.ipynb)"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}